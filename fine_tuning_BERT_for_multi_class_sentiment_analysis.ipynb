{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgREhnI7oldGuMCklLZZe5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zuhair0000/fine_tuning_course/blob/main/fine_tuning_BERT_for_multi_class_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "mfpRYrX-_8kk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZelK5EeVFAyM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/refs/heads/master/twitter_multi_class_sentiment.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "abMFZ9EQFPlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6NM4L6K2FUkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Jxl4RiIZFWfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "R8C-j5i7Faer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = df['label_name'].value_counts(ascending=True)\n",
        "label_counts.plot.barh()\n",
        "plt.title(\"Frequency of classes\")"
      ],
      "metadata": {
        "id": "CcCwdZUVFpQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['words per tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot('words per tweet', by='label_name')"
      ],
      "metadata": {
        "id": "oNGx7ofEGFi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WGKD7EwVF2IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. AutoTokenizer (The Translator)\n",
        "\n",
        "Computers cannot read English. They only read numbers.\n",
        "\n",
        "* The Job: This tool takes your sentence (\"I love AI\") and chops it into pieces (tokens). It then looks up those pieces in a massive dictionary and replaces them with ID numbers (e.g., [101, 234, 567...]).\n",
        "\n",
        "* Why \"Auto\"? Every model (BERT, RoBERTa, GPT) has its own unique dictionary. You can't use a GPT dictionary for a BERT model. AutoTokenizer looks at your model name and automatically pulls the correct dictionary."
      ],
      "metadata": {
        "id": "tm00Nn1NACIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "text = 'I love machine learning! Tokenizatoin is awesome'\n",
        "\n",
        "encode_text = tokenizer(text)\n",
        "print((encode_text))"
      ],
      "metadata": {
        "id": "lRR28VxSGWs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "pe1K29PDshY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader and Train Test Split"
      ],
      "metadata": {
        "id": "CWDOPRTds6eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.3, stratify=df['label_name'])\n",
        "test, validation = train_test_split(test, test_size=1/3, stratify=test['label_name'])\n",
        "\n",
        "train.shape, test.shape, validation.shape"
      ],
      "metadata": {
        "id": "FxSsvk4etIT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting to Hugging Face Format**\n",
        "Pandas is great for humans, but Hugging Face models prefer their own Dataset object format because it's faster for training.\n",
        "\n",
        "\n",
        "1. Dataset.from_pandas: Converts the Pandas DataFrame into a Hugging Face Dataset.\n",
        "\n",
        "2. preserve_index=False: Pandas creates a numbered index (0, 1, 2...) on the left. We don't need this extra column cluttering our AI data, so we throw it away.\n",
        "\n",
        "3. DatasetDict: A container that holds all three splits (train, test, validation) in one variable, making it easy to access them later (e.g., dataset['train']).\n",
        "\n"
      ],
      "metadata": {
        "id": "yaoKFjGA6kzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "dataset = DatasetDict(\n",
        "    {'train': Dataset.from_pandas(train, preserve_index=False),\n",
        "     'test': Dataset.from_pandas(test, preserve_index=False),\n",
        "     'validation': Dataset.from_pandas(validation, preserve_index=False)\n",
        "     }\n",
        ")\n",
        "dataset"
      ],
      "metadata": {
        "id": "pnHY4QNTtsme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "vSHv4Qdj3VBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "VmJ-sHFM3ZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  temp = tokenizer(batch['text'], padding=True, truncation=True)\n",
        "  return temp\n",
        "\n",
        "print(tokenize(dataset['train'][:2]))"
      ],
      "metadata": {
        "id": "FN5zu56R3hBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "twPvyHbK30xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_encoded"
      ],
      "metadata": {
        "id": "ZED5gd854D87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {x['label_name']:x['label'] for x in dataset['train']}\n",
        "id2label = {v:k for k, v in label2id.items()}\n",
        "\n",
        "label2id, id2label"
      ],
      "metadata": {
        "id": "_uohYyKu4SSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. AutoModel (The Brain)\n",
        "\n",
        "* The Job: This loads the raw, pre-trained BERT brain. This brain has read all of Wikipedia. It understands grammar, context, and synonyms.\n",
        "\n",
        "* The Catch: It only understands language. It doesn't know you want to do \"Sentiment Analysis.\" If you feed it a sentence, it just spits out a mathematical representation of that sentence. It doesn't give you a label like \"Happy\" or \"Sad.\""
      ],
      "metadata": {
        "id": "23lYAWO-AUPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "mBid2PAn42yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "lnUmqCXk-Rpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "8vr_VFBS-Xzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. AutoConfig (The Blueprint)\n",
        "* **The Job**: This is a settings file. It tells the code: \"How many labels do we have?\" (In your case, you have 6 emotions). It also remembers which number corresponds to which emotion (e.g., 0 = Sadness, 1 = Joy).\n",
        "\n",
        "* **Why we need it**: We need to inject this map (label2id) into the model so it knows that it is choosing between 6 specific options, not 2 or 100.\n",
        "\n",
        "# 4. AutoModelForSequenceClassification (The Specialist)\n",
        "* **The Job**: This is the most important one for you. It takes the AutoModel (the raw brain) and glues a strictly defined \"Head\" on top of it.\n",
        "\n",
        "* **The Head**: This is a final layer of math that takes the brain's deep thoughts and forces them into one of your 6 categories.\n",
        "\n",
        "# **Difference**:\n",
        "\n",
        "* **AutoModel**: Outputs a complex vector of numbers (the \"hidden state\").\n",
        "\n",
        "* **AutoModelForSequenceClassification**: Outputs scores for your labels (e.g., Joy: 95%, Sadness: 2%, etc.)."
      ],
      "metadata": {
        "id": "VJ-V-UUJAgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "num_labels = len(label2id)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=config).to(device)"
      ],
      "metadata": {
        "id": "bT6P4xoD-cT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "qvUI-HpWE4k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "training_dir = 'bert_base_train_dir'\n",
        "training_args = TrainingArguments(output_dir = training_dir,\n",
        "                                  # overwrite_output_dir = True,\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  weight_decay = 0.01,\n",
        "                                  eval_strategy = 'epoch',\n",
        "                                  disable_tqdm = False\n",
        "                                  )\n",
        "\n"
      ],
      "metadata": {
        "id": "EqREas1DFECS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "wXCgSr96Hf9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics_evaluate(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  return accuracy.compute(predictions=predictions, reference=labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "e2pqCHHqG8C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "\n",
        "  return{\n",
        "      'accuracy': acc,\n",
        "      \"f1\": f1\n",
        "  }"
      ],
      "metadata": {
        "id": "P35A8qDxHeCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model and Trainer\n",
        "\n",
        "# **The Trainer (The Manager)**\n",
        "In the old days (3+ years ago), you had to write a for loop that manually fed data to the model, calculated the error, updated the weights, and repeated. It was 50 lines of complex math code.\n",
        "\n",
        "* ### **TrainingArguments**\n",
        "This is just a configuration list. You are telling the manager:\n",
        "\n",
        "num_train_epochs=2: \"Read the entire textbook (dataset) 2 times.\"\n",
        "\n",
        "batch_size=64: \"Study 64 flashcards at a time before taking a break to update your brain.\"\n",
        "\n",
        "output_dir: \"Save your progress here.\"\n",
        "\n",
        "* ### **Trainer**\n",
        "This is the magic wrapper. You give it:\n",
        "\n",
        "1. The Model (The student)\n",
        "\n",
        "2. The Args (The schedule)\n",
        "\n",
        "3. The Data (The textbooks)\n",
        "\n",
        "4. compute_metrics (The exam)\n",
        "\n",
        "The Trainer handles all the looping, the GPU management, and the progress bars for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "VQbvHFfVIrFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotion_encoded['train'],\n",
        "                  eval_dataset=emotion_encoded['validation'],\n",
        "                  data_collator=data_collator\n",
        "                  )"
      ],
      "metadata": {
        "id": "qztaRmb0Ixx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qA2NKYUVJd09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "ekpAnHYpJfjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(emotion_encoded['test'])\n",
        "preds_output.metrics"
      ],
      "metadata": {
        "id": "bs1sSD3w2YhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = emotion_encoded['test'][:]['label']"
      ],
      "metadata": {
        "id": "cV95jU8d2gmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "61A6ue2Q2k-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wq99ksoV3jt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(cm, annot=True, xticklabels=label2id.keys(), yticklabels=label2id.keys(), fmt='d', cbar=False)"
      ],
      "metadata": {
        "id": "VHoT2eOD4JyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'I am super sad today'\n",
        "\n",
        "def get_predition(text):\n",
        "  input_encoded = tokenizer(text, return_tensors='pt').to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**input_encoded)\n",
        "\n",
        "  logits = outputs.logits\n",
        "  pred = torch.argmax(logits, dim=1).item()\n",
        "  return id2label[pred]"
      ],
      "metadata": {
        "id": "zQOOKwWH7GDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_predition(\"I love you\")"
      ],
      "metadata": {
        "id": "vc5MxluC8YsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('bert-base-uncased-sentiment-model')"
      ],
      "metadata": {
        "id": "ElPZ-Uzz8xGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('text-classification', mdoel='bert-base-uncased-sentiment-model')\n",
        "\n",
        "classifier(text)"
      ],
      "metadata": {
        "id": "xrRNmzct9WP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier('i love you')"
      ],
      "metadata": {
        "id": "8CfkX0vs-C-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2EFd4bQi-R9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}